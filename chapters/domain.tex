\section{Введение в предметную область}
Около 10 лет назад история развития компьютерной графики реального времени потерпела кардинальный поворот с выходом графических API нового поколения, DirectX12, Vulkan и Metal.
Их предшественники, OpenGL и DirectX ранних версий, основывались на идее так называемого <<толстого>> драйвера.
Дизайн этих API старался максимально скрыть принципы работы видеокарт, предоставляя пользователям простой, но достаточно ограниченный инструмент для разработки графических приложений реального времени.
По мере развития индустрии компьютерной графики, разработчики приложений всё чаще сталкивались с ограничениями этого дизайна, а простота дизайна всё больше жертвовалась в пользу поддержки новых возможностей различных типов видеокарт.
Так, например, печально известна неоправданная сложность разработки трёхмерных приложений для мобильных платформ с использованием <<OpenGL for Embedded Systems>>, вызванная спецификой графических ускорителей, используемых на этих платформах.

Главной целью дизайна графических API нового поколения было избавление от накладных расходов сложных абстракций, вследствие чего произошёл отказ от <<толстых>> драйверов в пользу раскрытия всё большего числа внутренних деталей работы GPU.
Доступ к низкоуровневым механизмам графических ускорителей позволил приложениям лучше адаптироваться под конкретные устройства, рациональнее использовать доступные ресурсы, и, как следствие, достигать большего качества и производительности.
Однако сложность новых API требует от разработчика сильно более структурированного подхода к разработке приложений, дизайна собственных абстракций, собственных алгоритмов и систем управления различными ресурсами.
В следующем подразделе более детально освещены различные аспекты перехода к новым API, а также проблемы, возникающие при разработке приложений с их использованием.

\subsection{Аспекты разработки графических приложений реального времени в старых и новых API}
\subsubsection{Управление памятью транзиентных ресурсов}
Главный интерес в рамках данной работы составляют кардинальные изменения в работе с видеопамятью.
В процессе вычисления картинки одного кадра любое нетривиальное приложение использует \textit{транзиентные ресурсы} "--- промежуточные хранилища данных, содержимое которых не требуется после окончания вычисления кадра, либо требуется лишь в процессе вычисления следующего кадра.
Как правило, подобные ресурсы являются картинками с разрешением кратным разрешению монитора пользователя.
Из этого следует, что при переходе от 1080p мониторов к 4K мониторам потребление памяти транзиентными ресурсами возрастает в 4 раза, что обуславливает нужду в эффективном её переиспользовании.
Старые графические API полностью скрывали управление памятью GPU от пользователя, предоставляя лишь функции создания и удаления конкретных ресурсов.
За годы существования этой абстракции образовалось 3 основных подхода к эффективному управлению памятью транзиентных ресурсов.

Самым простым подходом является выделение и освобождение транзиентных ресурсов по ходу их нужды при помощи соответствующих вызовов графического API.
Этот подход фактически идентичен выделению памяти в различных языках программирования: драйвер операционной системы содержит аллокатор, на который пользователь перекладывает обязанность управления памятью и другими ресурсами GPU, аналогично аллокациям на куче в языке C.
Системный аллокатор переиспользует освободившуюся память, тем самым достигая низкого её потребления.
Однако такой подход не масштабируется на более сложные приложения.
Во-первых, известны нижние оценки на качество работы интерактивных аллокаторов (см. \cite{robson1971estimate}), на практике выражающиеся как фрагментация кучи.
Во-вторых, как правило, и создание, и освобождение ресурсов являются весьма дорогими операциями вследствие деталей реализации драйверов.

В некотором смысле противоположным подходом служит отказ от переиспользования памяти.
Все транзиентные ресурсы создаются заранее и не удаляются в ходе работы приложения.
Очевидно, что с повышением сложности приложения такой подход перестаёт быть применимым, что иногда приводит к попыткам вручную переиспользовать некоторые выделенные объекты.
Это, в свою очередь, приводит к чрезвычайно сложному для понимания коду, усложняя и замедляя работу над самим приложением.

Наконец, наиболее практичным подходом является техника \textit{пулирования} ресурсов.
Вся программа работает с объектом называемым \textit{пулом}, отвечающим за выделение и освобождение ресурсов.
Пул использует механизмы драйвера для выделения новых ресурсов, но вместо освобождения ресурсов в драйвер хранит список неиспользуемых ресурсов конкретного типа (в понятие тип, как правило, входит разрешение для текстур и размер для буферов соответственно, а также все флаги свойств ресурса).
Последующие запросы на выделение ресурсов обслуживаются в первую очередь из списка неиспользуемых, и только исчерпав его выделяются новые ресурсы посредством драйвера операционной системы.
Данный подход был оптимален до появления современных низкоуровневых графических API.
Однако в настоящее время хорошо заметен его главный недостаток: память не переиспользуется между ресурсами разных типов.

В современных же графических API предоставляется прямой, неограниченный доступ к памяти GPU.
Приложение может выделять \textit{кучи}, последовательности страниц виртуальной видеопамяти, и затем создавать ресурсы на конкретных адресах в рамках конкретной кучи.
Стоит отметить, что пересечение используемых разными ресурсами регионов кучи не запрещается, хоть поведение при одновременном использовании таких ресурсов не определено.
Фактически, это нововведение перекладывает ответственность по написанию аллокатора ресурсов с разработчиков драйвера на разработчиков приложения, что можно сравнить с разработкой на языке C, используя лишь системные вызовы POSIX \inlcpp{mmap} и \inlcpp{munmap} вместо аллокатора библиотеки glibc.
С одной стороны, это сильно усложняет разработку простых приложений.
Вследствие этого компания AMD открыла исходный код аллокатора из своих драйверов \cite{VMA}, к использованию которого нередко прибегают даже в промышленных приложениях, что, конечно же, возвращает статус-кво старых графических API.
С другой стороны, это даёт возможность разработчикам более эффективно распоряжаться видеопамятью в различных подсистемах приложения, в частности, позволяя построить в некотором смысле оптимальное расписание аллокации транзиентных ресурсов, чему в первую очередь и посвящена данная работа.

\subsubsection{Отправка команд GPU}
Работа с любыми внешними по отношению к центральному процессору компонентами компьютера по своей природе асинхронна.
Передача данных по проводам занимает время, как и их обработка на внешнем устройстве.
Заставлять ядра центрального процессора простаивать в ожидании отклика от внешнего устройства "--- непозволительная растрата ресурсов.
Не исключение и графические ускорители.
Низкоуровневым инструментом для общения GPU и операционной системы служат \textit{списки команд}, состоящие из команд отрисовки, запуска вычислений, синхронизации, копирования данных, и прочих.
В случае если центральному процессору необходимо дождаться результата каких-либо вычислений на GPU, ожидание необходимо делать вручную, используя аппаратные сигналы о прогрессе от видеоускорителя.

В старых API асинхронная природа вычислений на GPU скрывалась за абстракцией \textit{мгновенного режима} (от англ. immediate mode).
Драйвер создавал видимость мгновенного выполнения всех команд GPU, представлявших собой функции.
Примитивы синхронизации в рамках GPU, а также между GPU и CPU, вставлялись автоматически, что не редко приводило к непредсказуемой производительности кода.
Более того, производительность крупных приложений могла упираться в скорость записи командных буферов внутри драйвера.
Естественным способом решения этой проблемы была бы параллельная их запись, но машина состояний внутри драйверов старых графических API была фундаментально однопоточной структурой.
Далее, в какой-то момент времени графические ускорители начали поддерживать параллельную обработку нескольких очередей команд.
Эта возможность может давать прирост производительности при слабой загрузке вычислительных модулей GPU исполняемыми командами.
Дизайн старых API не был рассчитан на поддержку таких возможностей аппаратуры, что сильно усложняло работу с этим функционалом.

С приходом новых графических API фактически все проблемы с отправкой команд были решены, а точнее ответственность по их решению была переложена на разработчиков приложений.
Новые API предоставляют пользователю прямой доступ к спискам команд, примитивам синхронизации и очередям исполнения команд.
Однако как и в случае с прямым доступом к памяти, работа напрямую с предоставляемыми графическим API абстракциями не является практичной, необходима разработка собственных абстракций для удобной записи команд.

\subsubsection{Управление кешами GPU и состоянием ресурсов}
Характерным отличием графических ускорителей от центральных процессоров является отсутствие гарантий когерентности кешей, и вследствие чего необходимость в ручную делать их инвалидацию и сброс.
Однако старые графические API скрывали эту особенность аппаратуры, автоматически отслеживая состояние ресурса и вставляя соответствующие команды синхронизации в список команд.
Недостаток такого подхода заключается в отсутствие невозможности предсказывать последующие команды пользователя на уровне драйвера, что не редко приводит к исполнению команд синхронизации в неоптимальный момент времени.
Усугубляет ситуацию тот факт, что некоторые GPU используют различные оптимизации формата хранения ресурсов при их использовании конкретным образом, и переход между разными оптимизированными состояниями приводит к простою вычислительных ресурсов GPU.

В новых же графических API ответственность за отслеживание состояния ресурсов и кешей переложена на пользователя посредством абстракции \textit{барьеров}.
Барьеры служат главным примитивом синхронизации в рамках GPU, управления кешами и состояниями ресурсов.
Однако расстановка барьеров в корректных и оптимальных местах порой оказывается далеко не тривиальной задачей, требующей от пользователя глобального понимания работы всей системы.
Это делает модуляризацию приложения невозможным без введения специальных механизмов для расстановки барьеров.

\subsection{Кадровые графы}
Сложно отследить появление понятия вычислительного графа, однако первым приложением этой техники в контексте графических приложений реального времени считается игровой движок Frostbite компании EA, о чём было объявлено в 2017 году на конференции Game Developers Conference \cite{FrostbiteGdcTalk}.
С тех пор большая часть коммерческих движков перешла на архитектуру, основанную на кадровом графе, о чём подробнее в следующем разделе.
Причина этого перехода следующая: наличие кадрового графа в виде данных позволяет решить все вышеописанные проблемы, появившиеся с приходом новых графических API, при этом сделать это оптимальнее чем позволяли встроенные в драйвер механизмы старых API.

Уточним используемую в дальнейшем терминологию.
\textit{Кадровым графом} назовём конкретный набор вершин, рёбер и других данных, определяемый настройками и спецификой приложения, и задающий глобальную структуру процесса вычисления одного кадра.
\textit{Рантаймом} кадровых графов будем называть программное решение, принимающее на вход конкретный кадровый граф и позволяющее его \textit{компилировать}, запускать и, возможно, редактировать.
Процесс компиляции кадрового графа "--- некоторый набор действий и вычислений, которые необходимо совершить перед запуском кадрового графа.
Конкретный набор данных, задающий кадровый граф, определяется дизайном конкретного рантайма, как и специфика процессов компиляции, запуска, а также дополнительный функционал, предоставляемый пользователям рантайма, а именно разработчикам алгоритмов визуализации сцены.
Пространство дизайна рантайма кадровых графов весьма широко, но независимо от конкретных решений, рантайм будет принимать на вход набор вершин, каждая из которых содержит \textit{функцию запуска}, инициирующую некоторые вычисления на GPU, и список используемых функцией запуска ресурсов с дополнительной информацией о способе использования.
Рёбра же графа, как правило, не задаются явно, а создаются автоматически, например, между вершиной создающей некоторый ресурс и читающей этот ресурс вершиной.
Абстрагируясь от конкретики, опишем как именно архитектура, основанная на кадровом графе, позволяет решить описанные выше проблемы.

\subsubsection{Управление памятью в кадровых графах}
Во-первых, имея в виде данных глобальную информацию об использовании ресурсов на протяжении всего кадра, вопрос управления памятью GPU сводиться к неинтерактивной вариации хорошо известной в литературе задачи динамической аллокации памяти \cite[с. 226]{10.5555/574848}.
В отсутствие же глобальной информации управление памятью является интерактивной вариацией этой задачи.
Как уже было упомянуто ранее, известно, что алгоритмы для интерактивной вариации этой задачи работают качественно хуже, чем для статической (см. \cite{robson1971estimate}), и более того, создание ресурсов GPU "--- достаточно дорогая операция, а качественные алгоритмы решения интерактивной динамической аллокации памяти занимают значительное время.
Эти факторы делают решение неинтерактивной вариации этой задачи единожды в момент компиляции кадрового графа привлекательной идеей, и наоборот, скорее всего любое решение оптимально управляющее памятью транзиентных ресурсов в том или ином виде будет сводится к кадровому графу.

\subsubsection{Кеши и состояние ресурсов в кадровом графе}
Во-вторых, если рантайм требует от пользователей указывать конкретный способ использования ресурсов внутри вершины, то в процессе запуска кадрового графа становится возможным автоматически расставлять барьеры.
Если ресурс был создан и заполнен данными посредством рендеринга вершиной $A$, а затем после запуска некоторого количества других вершин был семплирован вершиной $B$, то рантайм обязан поставить барьер переводящий ресурс из состояния пригодного для рендеринга в состояние пригодное для семплирования.
Однако, из-за наличия нескольких промежуточных вершин, у рантайма есть выбор, в какой конкретно момент поставить барьер.
Этот выбор может влиять на производительность из-за конвейеризации вычислений на современных графических ускорителях, а значит можно сформулировать задачу дискретной оптимизации расстановки барьеров с целью минимизации простоев вычислительных модулей GPU.
Впрочем, постановка и решение такой задачи выходит за рамки данной работы.

\subsubsection{Кадровые графы и GPU архитектуры TBDR}
В-третьих, важной особенностью современных графических API, не упомянутой ранее, является поддержка специфичной для портативных и мобильных устройств архитектуры графических ускорителей, называемой <<Tile Based Deferred Renderer>> (TBDR).
Не вдаваясь в детали принципов работы TBDR, старые графические API были абсолютно не рассчитаны на подобные возможности апаратуры, что приводило к непредсказуемому влиянию изменений в коде на производительность, а также делало некоторые техники визуализации вроде отложенного освещения неприменимыми на подобных устройствах.
В новых же API был предоставлен почти полный контроль над механизмами работы TBDR, что с одной стороны решило эти проблемы, но с другой стороны сильно усложнило процесс разработки из-за введения понятия \textit{рендер"=пасса} \cite[раздел~8]{VulkanSpec}.
Введение слоя абстракции над графическим API в виде кадрового графа позволяет одновременно и упростить интерфейс предоставляемый пользователю для работы с TBDR и рендер"=пассами, и сохранить предсказуемость производительности, отчасти путём предоставления инструментов визуализации структуры графа.

\subsubsection{Отправка команд GPU из кадрового графа}
В-четвёртых, как уже было упомянуто выше, современные GPU часто предоставляют разработчикам несколько очередей для отправки команд, что позволяет лучше насытить вычислительные модули в ситуации когда выполняемые команды не требуют стопроцентного использования всех возможностей ускорителя.
Рантайм кадровых графов может помочь автоматизировать этот процесс, заранее выбирая стратегию планирования имеющихся вершин на имеющиеся очереди команд.
Далее, даже в рамках одной очереди команд не редко имеет смысл чередовать команды от независимых ветвей графа с целью лучше насытить вычислительные ресурсы GPU полезной работой.
Более того, само исполнение вершин кадрового графа для получения списков команд рантайм может производить параллельно для независимых ветвей графа, что может понизить время затрачиваемое на кадр на центральном процессоре.
В данной работе, однако, более глубоко данный вопрос не освещается.

\subsubsection{Архитектурные аспекты кадровых графов}
Наконец, вероятно самым важным фактором в распространении кадровых графов послужили архитектурные преимущества этого подхода.
Как было сказано ранее, рёбра графа обычно задаются пользователями рантайма неявно, посредством ресурсных зависимостей.
Это позволяет добиться низкой связности различных подсистем приложения: модулям не требуется знать о прочей системе ничего, кроме названий ресурсов и публичного API рантайма кадровых графов.
Более того, рантайм может автоматически обнаруживать некорректные конфигурации приложения, в которых тем или иным модулям не хватает необходимых ресурсных зависимостей, отключая соответствующие модули автоматически.

Конечно же, далеко не все имплементации рантаймов кадровых графов содержат решения всех перечисленных проблем, и не всегда в описанном выше виде.
Некоторые же имплементации содержат уникальный для них функционал, решающий специфичные для конкретной области проблемы.
Обзор существующих комплексных решений содержится в следующем разделе работы.
